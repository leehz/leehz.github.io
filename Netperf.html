<!doctype html PUBLIC "-//IETF//DTD HTML//EN">
<HTML>
<!-- HTML generated by Cyberleaf(tm) 1.0.0 -->

<BODY>
<UL PLAIN>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.6R2DBD.2" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.0">Section 0. The Legal Stuff</A>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.6R2DBD.4" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Section 1. Introduction</A>
<UL PLAIN>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.6R2DBD.5" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Conventions and Definitions</A></A>
</UL>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.6R2DBD.7" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.6">Section 2. Installing Netperf</A>
<UL PLAIN>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.7R2DBD.8" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Getting the netperf bits from the Internet</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.7R2DBD.9" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Installing the bits</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.7R2DBD.A" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Verifying the bits</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.7R2DBD.B" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Running netserver as a standalone Daemon</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.7R2DBD.C" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Final Customization</A></A>
</UL>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.7R2DBD.E" NAME="0.1.2Z141Z1.SUJSTF.7R2DBD.D">Section 3. The Design of Netperf</A>
<UL PLAIN>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.7R2DBD.F" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Design Basics</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.7R2DBD.G" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">CPU Utilization</A></A>
</UL>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.8R2DBD.I" NAME="0.1.2Z141Z1.SUJSTF.7R2DBD.H">Section 4. Using Netperf to measure bulk data transfer performance</A>
<UL PLAIN>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.8R2DBD.J" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">TCP Stream Performance</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.8R2DBD.K" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">UDP Stream Performance</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.8R2DBD.L" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">DLPI Connection Oriented Stream Performance</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.8R2DBD.M" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">DLPI Connectionless Stream</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.8R2DBD.N" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Unix Domain Stream Sockets</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.8R2DBD.O" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Unix Domain Datagram Sockets</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.8R2DBD.P" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Fore ATM API Stream</A></A>
</UL>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.8R2DBD.R" NAME="0.1.2Z141Z1.SUJSTF.8R2DBD.Q">Section 5. Using Netperf to measure request/response performance</A>
<UL PLAIN>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.9R2DBD.S" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">TCP Request/Response Performance</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.9R2DBD.T" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">UDP Request/Response Performance</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.9R2DBD.U" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">DLPI Connection Oriented Request/Response Performance</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.9R2DBD.V" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">DLPI Connectionless Request/Response Performance</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.9R2DBD.W" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Unix Domain Stream Socket Request/Response Performance</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.9R2DBD.X" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Unix Domain Datagram Socket Request/Response Performance</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.9R2DBD.Y" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Fore ATM API Request/Response Performance</A></A>
</UL>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.9R2DBD.01" NAME="0.1.2Z141Z1.SUJSTF.9R2DBD.Z">Section 6. Other Netperf tests</A>
<UL PLAIN>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.9R2DBD.11" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">CPU rate calibration</A></A>
</UL>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.AR2DBD.31" NAME="0.1.2Z141Z1.SUJSTF.AR2DBD.21">Section 7. Netperf Command-line Options Reference</A>
<UL PLAIN>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.AR2DBD.41" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Command-line Options Syntax</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.AR2DBD.51" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">Global Options</A></A>
</UL>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.AR2DBD.71" NAME="0.1.2Z141Z1.SUJSTF.AR2DBD.61">Section 8. Netperf examples</A>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.AR2DBD.91" NAME="0.1.2Z141Z1.SUJSTF.AR2DBD.81">Section 9. Changes and Fixes in this Release of Netperf</A>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.AR2DBD.B1" NAME="0.1.2Z141Z1.SUJSTF.AR2DBD.A1">Section 10. Known Bugs and Misfeatures</A>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.AR2DBD.D1" NAME="0.1.2Z141Z1.SUJSTF.AR2DBD.C1">Section 11. Troubleshooting</A>
<UL PLAIN>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.AR2DBD.E1" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">establish_control: control socket connect failed: Connection refused</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.BR2DBD.F1" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">udp_send: data send error: Message too long <BR>
-or-<BR>
send_udp_rr: data send error: Message too long</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.BR2DBD.G1" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">put_control: acknowledgement error wanted 6 got 5<BR>
netperf: dl_open: could not sent control message, errno = 0<BR>
netperf: send_dlpi_co_stream: dlpi_stream data descriptor: Error 0</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.BR2DBD.H1" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">netperf: dl_open: open of /dev/foo failed, errno = 2<BR>
netperf: send_dlpi_co_stream: dlpi stream data descriptor: No such file or directory</A></A>
<LI><A NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3"><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.BR2DBD.I1" NAME="0.1.2Z141Z1.SUJSTF.6R2DBD.3">netperf: receive_response: no response received</A></A>
</UL>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.BR2DBD.K1" NAME="0.1.2Z141Z1.SUJSTF.BR2DBD.J1">Section 12. Glossary</A>
<LI><A HREF="Netperf.html#0.2.2Z141Z1.SUJSTF.BR2DBD.M1" NAME="0.1.2Z141Z1.SUJSTF.BR2DBD.L1">Section 13. The Netperf Database</A>
</UL>
<BR><IMG SRC="graphics/Netperffu04.gif"  ><BR>
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.6R2DBD.2">Section</A> 0. The Legal Stuff</H1>
<BR>
              Copyright (C) 1993,1994,1995 Hewlett-Packard Company<BR>
                         ALL RIGHTS RESERVED.<BR>
<BR>
  The enclosed software and documention includes copyrighted works of<BR>
  Hewlett-Packard Co. For as long as you comply with the following<BR>
  limitations, you are hereby authorized to (i) use, reproduce, and<BR>
  modify the software and documentation, and to (ii) distribute the<BR>
  software and documentation, including modifications, for<BR>
  non-commercial purposes only.<BR>
<BR>
  1.  The enclosed software and documentation is made available at no<BR>
      charge in order to advance the general development of<BR>
      high-performance networking products.<BR>
<BR>
  2.  You may not delete any copyright notices contained in the<BR>
      software or documentation. All hard copies, and copies in<BR>
      source code or object code form, of the software or<BR>
      documentation (including modifications) must contain at least<BR>
      one of the copyright notices.<BR>
<BR>
  3.  The enclosed software and documentation has not been subjected<BR>
      to testing and quality control and is not a Hewlett-Packard Co.<BR>
      product. At a future time, Hewlett-Packard Co. may or may not<BR>
      offer a version of the software and documentation as a product.<BR>
<BR>
  4.  THE SOFTWARE AND DOCUMENTATION IS PROVIDED &quot;AS IS&quot;.<BR>
      HEWLETT-PACKARD COMPANY DOES NOT WARRANT THAT THE USE,<BR>
      REPRODUCTION, MODIFICATION OR DISTRIBUTION OF THE SOFTWARE OR<BR>
      DOCUMENTATION WILL NOT INFRINGE A THIRD PARTY'S INTELLECTUAL<BR>
      PROPERTY RIGHTS. HP DOES NOT WARRANT THAT THE SOFTWARE OR<BR>
      DOCUMENTATION IS ERROR FREE. HP DISCLAIMS ALL WARRANTIES,<BR>
      EXPRESS AND IMPLIED, WITH REGARD TO THE SOFTWARE AND THE<BR>
      DOCUMENTATION. HP SPECIFICALLY DISCLAIMS ALL WARRANTIES OF<BR>
      MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.<BR>
<BR>
  5.  HEWLETT-PACKARD COMPANY WILL NOT IN ANY EVENT BE LIABLE FOR ANY<BR>
      DIRECT, INDIRECT, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES<BR>
      (INCLUDING LOST PROFITS) RELATED TO ANY USE, REPRODUCTION,<BR>
      MODIFICATION, OR DISTRIBUTION OF THE SOFTWARE OR DOCUMENTATION.<BR>

<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.6R2DBD.4">Section</A> 1. Introduction</H1>
Netperf is a benchmark that can be used to measure various aspects of networking 
performance. Its primary focus is on bulk data transfer and request/response performance 
using either TCP or UDP and the Berkeley Sockets interface. There are optional tests 
available to measure the performance of DLPI, Unix Domain Sockets, the Fore ATM API and 
the HP HiPPI LLA interface.
<P>
This tool is maintained and informally supported by the IND Networking Performance Team. 
It is <B>NOT</B> supported via any of the normal Hewlett-Packard support channels. You are free 
to make enhancements and modifications to this tool.
<P>
This document is organized (loosely) into several sections as follows:
<P>
<UL>
<LI>Section 1. is what you are reading right now.
<LI>Section 2. describes how to get the netperf bits and how to set-up your system to run 
netperf. It also describes a simple way to verify that the installation has been successful.
<LI>Section 3. describes the design of netperf.
<LI>Section 4. describes netperf's bulk data transfer tests and their command line options.
<LI>Section 5. describes netperf's request-response tests and their command options.
<LI>Section 6. describes some of the supporting test types of netperf and their command line 
options.
<LI>Section 7. provides a description of the global command-line options for netperf.
<LI>Section 8. provides some examples of netperf usage.
<LI>Section 9. lists the changes and fixes in this revision of netperf.
<LI>Section 10. lists several known problems with this revision of netperf.
<LI>Section 11. provides some troubleshooting assistance.
</UL>
We thank you in advance for your comments, and hope that you find this tool useful.
<P>
HP-IND  Networking Performance Team 
<P>
``How fast is it? It's so fast, that ...&quot; ;-)
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.6R2DBD.5">Conventions</A> and Definitions</B>
<P>
You may not be familiar with some of the conventions and definitions used by this document. 
Generally, items of particular importance, command line options, and commands will be in 
<B>boldface</B> type. Filenames and command line items requiring user substitution will appear in 
<I>italicized</I> type.
<P>
A <I>sizespec</I> is a one or two item list passed with a command line option that can set the value 
of one or two netperf parameters.  If you wish to set both parameters to separate values, items 
should be separated by a comma - Eg ``parm1,parm2&quot;. If you wish to set the first parameter 
without altering the value of the second, you should follow the first item with a comma - Eg 
``parm1,&quot;. Likewise, precede the item with a comma if you wish to set only the second 
parameter - Eg &quot;,parm2&quot;. An item without a comma will set both parameters. This last mode 
is the one most frequently used.
<P>
Netperf has two types of command line options. The first are global command line options. 
They are essentially any option that is not tied to a particular test, or group of tests. An example 
of a global command line option is the test type. The second options are test specific options. 
These are options which are only applicable to a particular test. An example of a test specific 
option would be the send socket buffer size for a TCP_STREAM test. Global command line 
options are specified first, test specific second. They must be separated from each other by a 
``--&quot; (two dashes). If you wish to give test specific options only, they must be preceded by 
``--&quot;. (EG ./netperf -- -m 1024)
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.6R2DBD.7">Section</A> 2. Installing Netperf</H1>
Netperf is distributed in source form. This is to allow installation on systems other than those 
to which the authors have access. There are two ways to install netperf. The first runs the 
netperf server program, netserver, as a child of inetd, which requires that the installer of 
netperf be able to edit the files <I>/etc/services</I> and <I>/etc/inetd.conf</I> (or their equivalent). The second 
is to run netserver as a standalone daemon. This second method does not require edit 
capabilities on  <I>/etc/services</I> and <I>/etc/inetd.conf</I>. but does mean that you must remember to run 
the netserver program explicitly.
<P>
This manual assumes that those wishing to measure networking performance already know 
how to use anonymous FTP.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.7R2DBD.8">Getting</A> the netperf bits from the Internet</B>
<P>
For those people connected to the Internet, netperf is available via WWW. If you are not 
connected to the Internet such that you can use WWW, then you may be able to retrieve netperf 
via FTP or an FTP mail server. If all else fails, you can send email to Netperf Request 
&lt;netperf-request@hpisrdq.cup.hp.com&gt;.
<P>
If you have a WWW browser, you can retrieve netperf from the Netperf Page. It is located at 
the URL http://www.cup.hp.com/netperf/NetperfPage.html. Follow the links from that page.
<P>
Netperf source bits are also available via anonymous FTP from <B>ftp.cup.hp.com</B> in the directory 
<I>dist/networking/benchmarks</I>.  You should use <B>binary mode</B> transfers when bringing over the bits 
as you will be grabbing the latest copy of this document along with the netperf C source files.
<P>
<B>NOTE: </B> Older versions of netperf are available via anonymous FTP from <B>col.hp.com</B> under 
the directory <I>dist/networking/benchmarks/</I>. It can also be found on other FTP servers on the 
Internet.
<P>
While the netperf source bits can be placed anywhere on the system, this manual will assume 
that the source bits are placed in the directory<I> /opt/netperf/src</I>.  Previous revisions of netperf 
were assumed to be placed in <I>/usr/etc/net_perf/src</I>, but this has been changed to better 
emphasize that netperf is not an official Hewlett-Packard product. You are free to place 
netperf wherever you like, provided that you make the necessary modifications to the scripts.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.7R2DBD.9">Installing</A> the bits</B>
<P>
Once you have placed the netperf source bits onto the system, it is necessary to compile them 
and perform some editing tasks. This section assumes that you have elected to install the 
benchmark server, netserver, as a child of inetd.
<P>
The netperf distribution includes a makefile which assumes the existence of the directory 
<I>/opt/netperf.</I> If you do not wish to have netperf installed there, it will be necessary for you to 
edit the makefile. To assist in this process, obvious markers have been placed in the makefile 
to indicate what must be changed. Also, some systems require different compile switches and 
libraries. For those systems where the requirements were known to the author, comments have 
been added to the makefile.
<P>
Once the makefile is customized as needed, simply enter the command:
<P>
<B>$ make install</B>
<P>
from within the netperf source directory. The netperf executables will be compiled and copied 
into <I>/opt/netperf</I> or the place you specified in the makefile. Make will also copy the sample 
script files into the same place and verify that they are set to be executable.
<P>
Now that the executables have been created, it is necessary to edit the<I> /etc/services</I> and 
<I>/etc/inetd.conf</I> files. If you have decided to keep the netperf executables someplace other than 
<I>/opt/netperf</I>, alter these lines accordingly. This editing step generally requires root access. If you 
do not have root access, or do not wish to install netperf as a child of inetd, skip to the 
subsection titled &quot;Running netserver as a standalone Daemon.&quot;
<P>
Add this line to the <I>/etc/services</I> file:
<P>
<B>netperf	12865/tcp</B>
<P>
Then add this line to the <I>/etc/inetd.conf</I> file:
<P>
<B>netperf stream tcp nowait root /opt/netperf/netserver netserver</B>
<P>
Once the files have been edited, it is necessary to have inetd re-configure itself. On an 
HP-UX system, this is accomplished with the command:
<P>
<B>$ /etc/inetd -c</B>
<P>
On some systems it is possible to get inetd to re-configure itself by sending it a SIGHUP with 
the kill(2) command:
<P>
<B>$ kill -HUP &lt;pid of inetd&gt;</B>
<P>
On other systems it might be necessary to kill and re-start the inet daemon. At this point, root 
access is no longer needed and you can proceed to the verification step. 
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.7R2DBD.A">Verifying</A> the bits</B>
<P>
To verify the installation of netperf, simply execute the command
<P>
<B> /opt/netperf/netperf</B>
<P>
A TCP_STREAM test of 10 seconds duration should be performed over the loopback 
interface.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.7R2DBD.B">Running</A> netserver as a standalone Daemon</B>
<P>
If you cannot install netperf as a child of inetd, you can run the netserver as a standalone 
daemon. Simply execute netserver with the &quot;-p &lt;port number&gt;&quot; option and it will happily 
start accepting requests on the port number you specify. If you specify a port number other than 
the normal netperf port number, you should remember to also specify &quot;-p &lt;portnum&gt;&quot; as 
a global command line option of netperf.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.7R2DBD.C">Final</A> Customization</B>
<P>
The scripts provided with the netperf distribution are written with the assumption that netperf 
is installed in <I>/opt/netperf</I>. If you have decided to install netperf in a different location, you will 
need to edit each of the script files and alter this line:
<P>
<B>NETHOME=/opt/netperf</B>
<P>
or one like it, to be something like:
<P>
<B>NETHOME=/my/netperf/location</B>
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.7R2DBD.E">Section</A> 3. The Design of Netperf</H1>
<B><A NAME="0.2.2Z141Z1.SUJSTF.7R2DBD.F">Design</A> Basics</B>
<P>
Netperf is designed around the basic client-server model. There are two executables - 
netperf and netserver. Generally you will only execute the netperf program - the netserver 
program will be invoked by the other system's inetd.
<P>
When you execute netperf, the first thing that will happen is the establishment of a control 
connection to the remote system. This connection will be used to pass test configuration 
information and results to and from the remote system. Regardless of the type of test being run, 
the control connection will be a TCP connection using BSD sockets.
<P>
Once the control connection is up and the configuration information has been passed, a 
separate connection will be opened for the measurement itself using the APIs and protocols 
appropriate for the test. The test will be performed, and the results will be displayed. 
<P>
Netperf places no traffic on the control connection while a test is in progress. Certain TCP 
options, such as SO_KEEPALIVE, if set as your system's default, may put packets out on the 
control connection.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.7R2DBD.G">CPU</A> Utilization</B>
<P>
CPU utilization is a frequently requested metric of networking performance. Unfortunately, 
it can also be one of the most difficult metrics to measure accurately. Netperf is designed to 
use one of several (perhaps platform dependent) CPU utilization measurement schemes. 
Depending on the CPU utilization measurement technique used, a unique single-letter code 
will be included in the CPU portion of the test banner for both the local and remote systems.
<P>
The default CPU measurement technique is based on pstat (-DPSTAT compilation only). 
This technique should work on most HP-UX systems, but it may under-report the CPU 
usage. The extent of this underreporting is not currently known. When pstat() is used to gather 
CPU utilization information, a &quot;P&quot; will be displayed in the test banner in the CPU column.
<P>
A second measurement technique is based on a counter inserted into the HP-UX kernel's idle 
loop. Whenever the system goes completely idle (from the kernel's perspective), this counter 
starts to increment. When the system is not idle, the counter stops incrementing. This counter's 
value is retrieved by reading from /dev/kmem - a process which generally requires superuser 
privileges. CPU utilization is determined by comparing the rate at which the counter 
increments when the system is idle to the rate when a test is running. The idle rate is 
re-computed for each test unless provided by the user (more information on CPU rates can 
be found in Section 6.)
<P>
This counter is not present in a production HP-UX kernel and must be compiled-in. Briefly, 
this entails adding a flag (-DIDLE_CNT) to the kernel makefile, removing a .o file, and 
recompiling the kernel. This cannot be done on a system lacking kernel sources. Furthermore, 
this technique cannot be used at all on non-HP systems unless the vendors in question 
implement a similar technique. The kernel idle counter is considered highly accurate. When 
it is used, a &quot;I&quot; will be displayed in the test banner in the CPU column.
<P>
One technique that could have been used was to fork a ``looperprocess&quot; which would run at 
a low priority and count much like the kernel idle counter mechanism. Presumably, this 
process would run only when there was nothing else for the system to do. Unfortunately, while 
this mechanism is likely more accurate than using pstat, it may have an impact on the 
measurement. This mechanism is not currently available in netperf. When it is implemented, 
the letter &quot;L&quot; will be the appropriate single-letter code.
<P>
Other codes may be included in later versions of netperf. When the CPU utilization 
mechanism is unknown, either a &quot;U&quot; or a &quot;?&quot; will be displayed.
<P>
Great care should be exercised when looking at CPU utilization. Be certain you are familiar 
with the technique being used, and its  implications. For example, a mechanism that is based 
solely on CPU charged to the netperf (netserver) process alone will likely under-report the 
real CPU utilization SIGNIFICANTLY. Much network processing takes place away from the 
user process context. Caveat Benchmarker!
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.8R2DBD.I">Section</A> 4. Using Netperf to measure bulk data transfer performance</H1>
The most common use of netperf is measuring bulk data transfer performance. This is also 
referred to as &quot;stream&quot; or &quot;unidirectional stream&quot; performance. Essentially, these tests will 
measure how fast one system can send data to another and/or how fast that other system can 
receive it.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.8R2DBD.J">TCP</A> Stream Performance</B>
<P>
The TCP stream performance test is the default test type for the netperf program. The simplest 
test is performed by entering the command:
<P>
<B>/opt/netperf/netperf -H <I>remotehost</I></B>
<P>
which will perform a 10 second test between the local system and the system identified by 
<I>remotehost</I>. The socket buffers on either end will be sized according to the systems' default and 
all TCP options (e.g. TCP_NODELAY) will be at their default settings.
<P>
To assist in measuring TCP stream performance, two script files are provided with the netperf 
distribution. They are <I>tcp_stream_script</I> and <I>tcp_range_script</I>. <I>Tcp_stream_script</I> will invoke 
netperf based on the setting of script variables controlling socket and send sizes. 
<I>Tcp_range_script</I> will perform a similar set of tests, with the difference being that where 
<I>tcp_stream_script</I> tests specific datapoints, <I>tcp_range_script</I> will perform tests at points within 
a specified range. 
<P>
If you would like to perform tests other than those done by the scripts, you can invoke netperf 
manually. Some of the options you will likely want to experiment with are:
<P>
-s	<I>sizespec	</I>which will set the local send and receive socket buffer sizes to the 
value(s) specified. [Default: system default socket buffer sizes]
<P>
-S	<I>sizespec</I>	which behaves just like -s but for the remote system 
<P>
-m	<I>value</I>	set the local send size to <I>value</I> bytes. [Default: local socket buffer 
size]
<P>
-M	<I>value</I>	which behaves like -m, setting the receive size for the remote 
system. [Default: remote receive socket buffer size]
<P>
-l	<I>value</I>	set the test length to<I> value</I> seconds when value is &gt; 0 and to 
|<I>value</I>| bytes when value is &lt; 0
<P>
-D		set the TCP_NODELAY option to true on both systems
<P>
This is not a complete list of options that can affect TCP stream performance, but it does cover 
those options that are used most often. A complete list of netperf options can be found in 
Section 7.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.8R2DBD.K">UDP</A> Stream Performance</B>
<P>
A UDP stream performance test is very similar to a TCP stream test. One difference is that 
the send size cannot be larger than the smaller of the local and remote socket buffer sizes. 
What this means is that you must make certain that when you specify the -m option, you use 
a value that is less than or equal to the socket buffer sizes (-s and -S). Also, since the UDP 
Stream test is not the default test, the -t <I>testname</I> option must be specified, with the testname 
set to UDP_STREAM. So, a simple UDP stream test command might look something like 
this:
<P>
<B>$ /opt/netperf/netperf -H <I>remotehost</I> -t UDP_STREAM -- -m 1024</B>
<P>
There is a script provided that performs various UDP stream performance tests. It is called 
<I>udp_stream_script</I>. As with TCP stream performance, you can use the script provided, or 
perform tests yourself to get datapoints not covered by the script.
<P>
<B>NOTE</B>: UDP is an unreliable protocol. It is important that you examine the results carefully 
as the reported send rate can be much higher than the actual receive rate. Great care should 
be taken when reporting UDP_STREAM test results to make sure they are not misleading. 
For example, one should <B>always</B> report both send and receive rates <B>together</B> for a 
UDP_STREAM test. If you are going to report a single number, you should report the receive 
rate.
<P>
<B>NOTE: </B> If you would like to &quot;pace&quot; the send rate of the UDP_STREAM test, add a 
-DINTERVALS to the makefile, do a &quot;make clean&quot; and re-compile. You can then use the 
-b and -w  global options to set the burst size (sends) and wait time (milliseconds) 
respectively.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.8R2DBD.L">DLPI</A> Connection Oriented Stream Performance</B>
<P>
<B>NOTE: </B> DLPI tests are not compiled-in by default with netperf. If you wish to measure 
performance over DLPI, you will need to add a -DDO_DLPI to the makefile and perhaps 
add to the ``LIBS=&quot; and re-compile netperf and netserver.
<P>
A DLPI Connection Oriented Stream test (DLCO_STREAM) looks very similar to a TCP 
Stream test - they both use reliable, connection oriented protocols. The DLPI test differs 
from the TCP test in that the message size must always be less than or equal to the local 
interface's MTU - DLPI does not provide TCP-style segmentation and reassembly.
<P>
The simplest DLPI Connection Oriented Stream test would look something like this:
<P>
<B>$ /opt/netperf/netperf -H <I>remotehost</I> -t DLCO_STREAM -- -m 1024 </B>
<P>
Here are some of the DLPI-specific command line options:
<P>
-D	<I>devspec</I>	specify the local and/or remote DLPI device file name(s) 
(fully-qualified). Syntax is the same as that of a <I>sizespec</I>.
<P>
-m	<I>value</I>	specify the send size, in bytes, for the local system. This must be 
less than or equal to the link MTU.
<P>
-M	<I>value</I>	which behaves like -m, setting the receive size for the remote 
system.
<P>
-p	<I>ppaspec</I>	set the local and/or remote DLPI PPA(s). Syntax is the same as 
that of a <I>sizespec</I>.
<P>
-r	<I>value</I>	specify the request size, in bytes, for the test.
<P>
-R	<I>value</I>	specify the response size, in bytes, for the test.
<P>
-s	<I>value</I>	specify the 802.2 SAP for the test. This should not conflict with 
any assigned SAP's.
<P>
-w	<I>sizespec</I>	specify the local send/recv window sizes in frames (where 
available). 
<P>
-W	<I>sizespec</I>	specify the remote send/recv window sizes in frames (where 
available).
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.8R2DBD.M">DLPI</A> Connectionless Stream</B>
<P>
<B>NOTE: </B> DLPI tests are not compiled-in by default with netperf. If you wish to measure 
performance over DLPI, you will need to add a -DDO_DLPI to the makefile and perhaps 
add to the ``LIBS=&quot; and re-compile netperf and netserver.
<P>
A DLPI Connectionless Stream test (DLCL_STREAM) is analogous to a UDP_STREAM 
test. They both make use of unreliable, connectionless transports. The DLPI test differs from 
the UDP test in that the message size must always be less than or equal to the link MTU - 
DLPI does not provide IP-like segmentation and reassembly functionality, and the netperf 
benchmark does not presume to provide one.
<P>
The simplest DLPI Connectionless Stream test command line would look something like this:
<P>
<B>$ /opt/netperf/netperf -H <I>remotehost</I> -t DLCL_STREAM -- -m 1024 </B>
<P>
Here are some of the DLPI-specific command line options for the DLCL_STREAM test:
<P>
-D	<I>devspec</I>	specify the local and/or remote DLPI device file name(s) 
(fully-qualified). Syntax is the same as that of a <I>sizespec</I>.
<P>
-m	<I>value</I>	specify the send size, in bytes, for the local system. This must be 
less than or equal to the link MTU.
<P>
-M	<I>value</I>	which behaves like -m, setting the receive size for the remote 
system.
<P>
-p	<I>ppaspec</I>	set the local and/or remote DLPI PPA(s). Syntax is the same as 
that of a <I>sizespec</I>.
<P>
-s	<I>value</I>	specify the 802.2 SAP for the test. This should not conflict with 
any assigned SAP's.
<P>
-w	<I>sizespec</I>	specify the local send/recv window sizes in frames (where 
available). 
<P>
-W	<I>sizespec</I>	specify the remote send/recv window sizes in frames (where 
available).
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.8R2DBD.N">Unix</A> Domain Stream Sockets</B>
<P>
<B>NOTE: </B> Unix Domain Socket tests are not compiled into netperf by default. If you wish to 
measure the performance of Unix Domain Sockets, you must recompile netperf and netserver 
with -DDO_UNIX added to the makefile.
<P>
A Unix Domain Stream Socket Stream test (STREAM_STREAM) is very much like a 
TCP_STREAM test.
<P>
The Simplest Unix Domain Stream Socket Stream test command line would look something 
like this:
<P>
<B>$ /opt/netperf/netperf -t STREAM_STREAM</B>
<P>
The -H global command line Option is not valid for a Unix Domain Socket test and should 
not be specified.
<P>
Here are some of the Unix Domain-specific command line options for the 
STREAM_STREAM test:
<P>
-m	<I>value</I>	set the local send size to <I>value</I> bytes. [Default: local socket buffer 
size]
<P>
-M	<I>value</I>	which behaves like -m, setting the receive size for the remote 
system. [Default: remote receive socket buffer size]
<P>
-p	<I>dirspec</I>	set the directory where pipes will be created. [Default: system 
default for the tempnam() call]
<P>
-s	<I>sizespec	</I>which will set the local send and receive socket buffer sizes to the 
value(s) specified. [Default: system default socket buffer sizes]
<P>
-S	<I>sizespec</I>	which behaves just like -s but for the remote system 
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.8R2DBD.O">Unix</A> Domain Datagram Sockets</B>
<P>
<B>NOTE: </B> Unix Domain Socket tests are not compiled into netperf by default. If you wish to 
measure the performance of Unix Domain Sockets, you must recompile netperf and netserver 
with -DDO_UNIX added to the makefile.
<P>
A Unix Domain Datagram Socket Stream test (DG_STREAM) is very much like a 
TCP_STREAM test except that message boundaries are preserved.
<P>
The Simplest Unix Domain Datagram Socket Stream test command line would look 
something like this:
<P>
<B>$ /opt/netperf/netperf -t DG_STREAM</B>
<P>
The -H global command line option is not valid for a Unix Domain Socket test and should 
not be specified. Here are some of the test specific command line options available in a 
DG_STREAM test.
<P>
-m	<I>value</I>	set the local send size to <I>value</I> bytes. [Default: local socket buffer 
size]
<P>
-M	<I>value</I>	which behaves like -m, setting the receive size for the remote 
system. [Default: remote receive socket buffer size]
<P>
-p	<I>dirspec</I>	set the directory where pipes will be created. [Default: system 
default for the tempnam() call]
<P>
-s	<I>sizespec	</I>which will set the local send and receive socket buffer sizes to the 
value(s) specified. [Default: system default socket buffer sizes]
<P>
-S	<I>sizespec</I>	which behaves just like -s but for the remote system 
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.8R2DBD.P">Fore</A> ATM API Stream</B>
<P>
<B>NOTE: </B> Fore ATM API tests are not compiled into netperf by default. If you wish to measure 
the performance of connections over the Fore ATM API, you must recompile netperf and 
netserver with -DDO_FORE added to the makefile.
<P>
A Fore ATM API Stream test (FORE_STREAM) is very much like a UDP_STREAM test. 
<P>
<B>NOTE</B>: The Fore ATM API exports an unreliable protocol. It is important that you examine 
the results carefully as the reported send rate can be much higher than the actual receive rate. 
Great care should be taken when reporting FORE_STREAM test results to make sure they 
are not misleading. For example, one should <B>always</B> report both send and receive rates 
<B>together</B> for a FORE_STREAM test. If you are going to report a single number, you should 
report the receive rate.
<P>
The simplest Fore ATM API Stream test command line would look something like this:
<P>
<B>$ /opt/netperf/netperf -t FORE_STREAM -H <I>remotehost</I> </B>
<P>
Here are some of the test specific command line options applicable to a FORE_STREAM 
test.
<P>
-a	<I>aal</I>	use the ATM Adaptation Layer number aal to encapsulate 
packets. Specifying 3 or 4 will yield AAL3/4, and 5 will yield 
AAL5. [Default: 5 -&gt; AAL5]
<P>
-b	<I>sizespec</I>	set the mean burst target and/or minimum in units of kilobit 
packets. The first value is target and the second is minimum. 
[Default: 0,0]
<P>
-d	<I>devspec</I>	set the name of the ATM device file to be opened. [Default: 
/dev/atm]
<P>
-m	<I>value</I>	set the local send size to <I>value</I> bytes. This must not be larger than 
the ATM MTU. [Default: ATM MTU]
<P>
-M	<I>value</I>	which behaves like -m, setting the receive size for the remote 
system. [Default: ATM MTU]
<P>
-p	<I>sizespec</I>	set the peak bandwidth target and/or minimum in units of 
kilobits/s. The first value is target and the second it minimum. 
[Default: 0,0 -&gt; network assigned]
<P>
-P	<I>sizespec</I>	set the mean bandwidth target and/or minimum in units of 
kilobits/s. The first value is target and the second is minimum. 
[Default: 0,0 -&gt; network assigned]
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.8R2DBD.R">Section</A> 5. Using Netperf to measure request/response performance</H1>
Request/response performance is the second area that can be investigated with netperf. 
Generally speaking, netperf request/response performance is quoted as &quot;transactions/s&quot; for 
a given request and response size. A transaction is defined as the exchange of a single request 
and a single response. From a transaction rate, one can infer one way and round-trip average 
latency.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.9R2DBD.S">TCP</A> Request/Response Performance</B>
<P>
The TCP request/response test can be invoked with netperf though the use of the -t option 
with an argument of TCP_RR. So, a ``default&quot; request/response command would look 
something like this:
<P>
<B>$ /opt/netperf/netperf -H <I>remotehost</I> -t TCP_RR</B>
<P>
and will use the system default socket buffer sizes, a default request size of 1 byte, and a default 
response size of 1 byte. 
<P>
As with the stream performance tests, a script is available to assist you in generating TCP 
request/response performance numbers. It is called<I> tcp_rr_script</I>. However, if you should need 
to generate numbers at points of you own choosing, these command line options will be of use:
<P>
-r	<I>sizespec</I>	set the request and/or response sizes based on <I>sizespec</I>.
<P>
-l	<I>value</I>	set the test duration based on <I>value</I>. For <I>value</I> &gt; 0, test duration 
will be <I>value</I> seconds. Otherwise, test duration will be |<I>value</I>| 
transactions.
<P>
-s	<I>sizespec	</I>which will set the local send and receive socket buffer sizes to the 
value(s) specified. [Default: system default socket buffer sizes]
<P>
-S	<I>sizespec</I>	which behaves just like -s but for the remote system 
<P>
-D		set the TCP_NODELAY option to true on both systems
<P>
The request and response sizes will be the buffer sizes posted to send and receive. The -m and 
-M options are not meaningful for a TCP_RR test.. As TCP is a stream protocol and not a 
message protocol, it is necessary to loop on receives until the entire message is delivered. The 
buffer pointer passed to the first receive for an individual transaction will be aligned and offset 
as requested by the user. It will be incremented by the number of bytes received each time until 
the entire request/response is received. The buffer pointer will be re-aligned and offset for 
the next transaction.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.9R2DBD.T">UDP</A> Request/Response Performance</B>
<P>
UDP request/response performance works just like TCP request/response performance. All 
the options available there are present here with the exception of the -D option; 
TCP_NODELAY has no meaning for a UDP test. To invoke a UDP request/response test, use 
an argument of UDP_RR with the -t option to produce a command like something like this:
<P>
<B>$ /opt/netperf/netperf -H <I>remotehost</I> -t UDP_RR</B>
<P>
Again, a script is provided which will generate results for some of the more common 
datapoints. It is named <I>udp_rr_script</I>.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.9R2DBD.U">DLPI</A> Connection Oriented Request/Response Performance</B>
<P>
<B>NOTE: </B> DLPI tests are not compiled into netperf by default. If you wish to measure the 
performance of DLPI, you must recompile netperf and netserver with -DDO_DLPI added 
to the makefile.
<P>
A DLPI Connection Oriented Request/Response test (DLCO_RR) looks much the same as 
any other request/response test. It performs a request/response test over a reliable connection. 
As with the other DLPI tests, there is no segmentation and reassembly, so all request and/or 
response sizes must be less than or equal to the link MTU.
<P>
A simple DLCO_RR test invocation would look something like this:
<P>
<B>$ /opt/netperf/netperf -H <I>remotehost</I> -t DLCO_RR </B>
<P>
Here are some of the DLPI-specific command line options:
<P>
-D	<I>devspec</I>	specify the local and/or remote DLPI device file name(s) 
(fully-qualified). Syntax is the same as that of a <I>sizespec</I>.
<P>
-p	<I>ppaspec</I>	set the local and/or remote DLPI PPA(s). Syntax is the same as 
that of a <I>sizespec</I>.
<P>
-r	<I>sizespec</I>	specify the request and/or response sizes, in bytes, for the test.
<P>
-s	<I>value</I>	specify the 802.2 SAP for the test. This should not conflict with 
any assigned SAP's.
<P>
-w	<I>sizespec</I>	specify the local send/recv window sizes in frames (where 
available). 
<P>
-W	<I>sizespec</I>	specify the remote send/recv window sizes in frames (where 
available).
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.9R2DBD.V">DLPI</A> Connectionless Request/Response Performance</B>
<P>
<B>NOTE: </B> DLPI tests are not compiled into netperf by default. If you wish to measure the 
performance of DLPI, you must recompile netperf and netserver with -DDO_DLPI added 
to the makefile.
<P>
A DLPI Connectionless Request/Response test (DLCL_RR) looks much the same as any 
other request/response test. It performs a request/response test over an unreliable connection. 
However, netperf does not have any sort of retransmission mechanism, so packet loss with this 
test will result in dramatically lowered performance results. As with the other DLPI tests, there 
is no segmentation and reassembly, so all request and/or response sizes must be less than or 
equal to the link MTU.
<P>
A simple DLCL_RR test invocation would look something like this:
<P>
<B>$ /opt/netperf/netperf -H <I>remotehost</I> -t DLCL_RR </B>
<P>
Here are some of the DLPI-specific command line options:
<P>
-D	<I>devspec</I>	specify the local and/or remote DLPI device file name(s) 
(fully-qualified). Syntax is the same as that of a <I>sizespec</I>.
<P>
-p	<I>ppaspec</I>	set the local and/or remote DLPI PPA(s). Syntax is the same as 
that of a <I>sizespec</I>.
<P>
-r	<I>sizespec</I>	specify the request and/or response sizes, in bytes, for the test.
<P>
-s	<I>value</I>	specify the 802.2 SAP for the test. This should not conflict with 
any assigned SAP's.
<P>
-w	<I>sizespec</I>	specify the local send/recv window sizes in frames (where 
available). 
<P>
-W	<I>sizespec</I>	specify the remote send/recv window sizes in frames (where 
available).
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.9R2DBD.W">Unix</A> Domain Stream Socket Request/Response Performance</B>
<P>
<B>NOTE: </B> Unix Domain Socket tests are not compiled into netperf by default. If you wish to 
measure the performance of Unix Domain Sockets, you must recompile netperf and netserver 
with -DDO_UNIX added to the makefile.
<P>
A Unix Domain Stream Socket Request/Response test (STREAM_RR) is very much like a 
TCP_RR test.
<P>
The STREAM_RR test command line would look something like this:
<P>
<B>$ /opt/netperf/netperf -t STREAM_RR</B>
<P>
The -H global command line option is not valid for a Unix Domain Socket test and should 
not be specified.
<P>
Here are some of the Unix Domain-specific command line options for the 
STREAM_STREAM test:
<P>
-p	<I>dirspec</I>	set the directory where pipes will be created. [Default: system 
default for the tempnam() call]
<P>
-r	<I>sizespec	</I>which will set the request and response sizes to the value(s) 
specified. [Default: 1 byte]
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.9R2DBD.X">Unix</A> Domain Datagram Socket Request/Response Performance</B>
<P>
<B>NOTE: </B> Unix Domain Socket tests are not compiled into netperf by default. If you wish to 
measure the performance of Unix Domain Sockets, you must recompile netperf and netserver 
with -DDO_UNIX added to the makefile.
<P>
The Simplest Unix Domain Datagram Socket Request/Response (DG_RR) test command 
line would look something like this:
<P>
<B>$ /opt/netperf/netperf -t DG_STREAM</B>
<P>
The -H global command line option is not valid for a Unix Domain Socket test and should 
not be specified. Here are some of the test specific command line options available in a 
DG_STREAM test.
<P>
-p	<I>dirspec</I>	set the directory where pipes will be created. [Default: system 
default for the tempnam() call]
<P>
-r	<I>sizespec	</I>set the request and/or response sizes to the value(s) specified. 
[Default: 1 byte]
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.9R2DBD.Y">Fore</A> ATM API Request/Response Performance</B>
<P>
<B>NOTE: </B> Fore ATM API tests are not compiled into netperf by default. If you wish to measure 
the performance of connections over the Fore ATM API, you must recompile netperf and 
netserver with -DDO_FORE added to the makefile.
<P>
A Fore ATM API Request/Response test (FORE_RR) is very much like a UDP_RR test. 
<P>
The simplest FORE_RR test command line would look something like this:
<P>
<B>$ /opt/netperf/netperf -t FORE_RR -H <I>remotehost</I> </B>
<P>
Here are some of the test specific command line options applicable to a FORE_STREAM 
test.
<P>
-a	<I>aal</I>	use the ATM Adaptation Layer number aal to encapsulate 
packets. Specifying 3 or 4 will yield AAL3/4, and 5 will yield 
AAL5. [Default: 5 -&gt; AAL5]
<P>
-b	<I>sizespec</I>	set the mean burst target and/or minimum in units of kilobit 
packets. The first value is target and the second is minimum. 
[Default: 0,0]
<P>
-d	<I>devspec</I>	set the name of the ATM device file to be opened. [Default: 
/dev/atm]
<P>
-p	<I>sizespec</I>	set the peak bandwidth target and/or minimum in units of 
kilobits/s. The first value is target and the second it minimum. 
[Default: 0,0 -&gt; network assigned]
<P>
-P	<I>sizespec</I>	set the mean bandwidth target and/or minimum in units of 
kilobits/s. The first value is target and the second is minimum. 
[Default: 0,0 -&gt; network assigned]
<P>
-r	<I>sizespec</I>	set the request and/or response sizes to the values specified 
[Default: 1 byte]
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.9R2DBD.01">Section</A> 6. Other Netperf tests</H1>
Apart from the usual performance tests, netperf contains some tests that can be used to 
streamline measurements. These tests range from CPU rate calibration (present) to host 
identification (future enhancement).
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.9R2DBD.11">CPU</A> rate calibration</B>
<P>
<B>NOTE: </B> This discussion of calibration is germane only for those systems with the Kernel Idle 
Counter in place. It is not germane for CPU utilization measured with pstat(). If in the future 
a looper process is introduced, this discussion would be germane for it as well.
<P>
In this context, a CPU rate is expressed not in clock frequencies, MIPS or MFLOPS, but simply 
how fast the system can count. There are two CPU rate calibrations tests. The first measures 
and displays the CPU rate for the local system. It is called LOC_CPU. The second test, 
REM_CPU, is exactly the same, except that it works on the system specified with the -H 
command line option. 
<P>
In and of themselves, these two tests are only arcanely interesting. However, they can be used 
to greatly speed-up test scripts. Remember that for CPU measurements, it is necessary to 
``calibrate&quot; the CPU or determine how fast it can count. This process takes forty (40) seconds 
for the local system and forty (40) seconds for the remote system. One can save the results of 
the CPU tests in shell variables and then use them as arguments to the -c and -C command 
line options. Passing-in a rate with the -c or -C option tells netperf that you already know 
the CPU rate, so it can skip the calibration steps. For example, the following shell fragment 
will determine the local CPU rate and use that for subsequent tests:
<P>
<B>$ LOC_RATE=`/opt/netperf/netperf -t LOC_CPU`</B>
<P>
<B>$ /opt/netperf/netperf -H somehost -c $LOC_RATE</B>
<P>
You should remember that CPU rates will vary from system to system. Generally, the best 
trade-off between time and accuracy is to perform the calibrations once in each script or 
session. The default scripts provided will use the LOC_CPU and REM_CPU tests to reduce 
the time overhead of CPU calibration.
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.AR2DBD.31">Section</A> 7. Netperf Command-line Options Reference</H1>
This section describes each of the global command-line options available in the netperf 
program. Essentially, it is an expanded version of the usage information displayed by netperf 
when invoked with the -h option in global command line option area.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.AR2DBD.41">Command-line</A> Options Syntax</B>
<P>
Revision 1.8 of netperf introduced enough new functionality to overrun the English alphabet 
for mnemonic command line option names. For this reason, command-line options were split 
in Revision 1.8. This split remains in Revision 1.9alpha. There are two types of netperf 
command-line options. They are ``global&quot; and ``test-specific.&quot; Both types are entered on the 
same command line, but they must be separated by a ``--&quot; for correct parsing. Global 
command line options come first, followed by test-specific. If only test-specific options are 
to be specified, they must be preceded by ``--&quot; or the results will be undefined.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.AR2DBD.51">Global</A> Options</B>
<P>
-a	sizespec	This option allows you to alter the send and receive buffer 
alignments on the local system. Changing the alignment of the 
buffers can force the system to use different copying schemes, 
which can have a measurable impact on performance. If the page 
size for the system was 4096 bytes, and you wanted to pass page 
aligned buffers beginning on page boundaries, you could use ``-a 
4096&quot;. The units for this option are whole bytes. [Default: 8 bytes]
<P>
-A	sizespec	This option is identical to the -a option with the exception that 
the alignments are altered for the remote system. 
<P>
-b	size	This option (-DINTERVALS compilation only) sets the size of 
a burst of packets in a _STREAM test. This can be used to &quot;pace&quot; 
the send rate when there is no flow-control provided by the 
protocol being measured.
<P>
-c	[rate]	This option will request CPU utilization and service demand 
calculations for the local system. If the optional rate parameter 
is specified, netperf will use that instead of calculating the rate 
itself. For more information on CPU utilization measurements 
with netperf, please consult Section 3. [Default: no CPU 
measurements]
<P>
-C	[rate]	This option is identical to the -c option with the exception that 
it requests CPU utilization for the remote system.
<P>
-d		This option will increase the quantity of debugging output 
displayed during a test. If debugging is set high enough, it may 
have a measurable impact on performance. Debugging 
information for the local system (the one running netperf) is 
printed to stdout. Debugging information for the remote system 
(the one running netserver) is sent to the file /tmp/netperf.debug 
[Default: no debugging]
<P>
-f	GMKgmk	This option can be used to change the units of measure for stream 
tests. The ``G&quot;, ``M&quot;, and ``K&quot; arguments will set the output units 
to 230, 220, and 210 bytes/s respectively. The ``g&quot;, ``m&quot;, and ``k&quot; 
arguments will set the output units to 109, 106, and 103 bits/s 
respectively. [Default: m - 106 bits/s)]
<P>
-h		This option causes netperf to display its usage string and exit.
<P>
-H	remotehost	This option sets the name of the remote system. It can be 
specified as either a hostname (e.g. foo.bar.baz) or an IP address 
(e.g. 1.2.3.4). [Default: localhost]
<P>
-l	testlen	With this option you can control the length of the test. If you 
specify a positive value for testlen, the test will run for  that many 
seconds. If you specify a negative value, the test will run for that 
many transactions for a request/response test, or that many bytes 
for a stream test. Some tests can only be timed. [Default: 10 
seconds]
<P>
-o	sizespec	The value passed with this option will be used as an offset from 
the alignment specified with the -a option. With this option you 
could, for example, pass buffers to the system that began 3 bytes 
after the beginning of a 4KB page (-a 4096 -o 3) [Default: 0 
bytes]
<P>
-O	sizespec	This option behaves just like the -o option but on the remote 
system. It works in conjunction with the -A option. [Default: 0 
bytes]
<P>
-p	portnum	You should use this option when the netserver program will be 
waiting at a port other than the default. This might be the case if 
you run netserver as a standalone process rather than a child of 
inetd. 
<P>
-P	0|1	If you do not want the test banner to be displayed, then use this 
option with an argument of 0. An situation where this might be 
useful would be where you repeat the same test configuration 
several times and do not want the banners cluttering things up. 
[Default: 1 - display test banners]
<P>
-t	testname	You should use this option to specify the test you wish to perform. 
As of this writing, the valid testnames are TCP_STREAM, 
TCP_RR, UDP_STREAM, UDP_RR, DLCO_STREAM, 
DLCO_RR, DLCL_STREAM, DLCL_RR, 
STREAM_STREAM, STREAM_RR, DG_STREAM, 
DG_RR, FORE_STREAM, FORE_RR, HIPPI_STREAM, 
HIPPI_RR LOC_CPU, and REM_CPU. [Default: 
TCP_STREAM]
<P>
-v	verbosity	This option can be used to set the verbosity level for the test. It 
can be used in conjunction with the -P option. If the verbosity is 
set to 0, then only the result of the test will be displayed. If CPU 
utilization numbers are requested for the local system, the result 
of the test will be local service demand. If remote CPU utilization 
is requested, then the result will be remote service demand. 
Otherwise, the result will be the measured thruput.
<P>
-V		This option will attempt to enable the copy-avoidance features 
of HP-UX 9.0 networking. [Default: no copy-avoidance 
attempted]
<P>
-w	time	This option (-DINTERVALS compilation only) will set the 
inter-burst time  to time milliseconds. The actual wait time may 
differ depending on the resolution of timers on the system being 
measured.
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.AR2DBD.71">Section</A> 8. Netperf examples</H1>
<B>NOTE: </B> These examples are from an older version of netperf and do not represent the split 
between global and test specific command line options.
<P>
<A HREF="graphics/Netperffl03.gif"><IMG SRC="graphics/Netperffl03th.gif" ></A>The next few pages contain annotated screen dumps of example netperf runs. After examining these examples, you should have a fairly good idea of how to interpret the output of netperf and what effect certain options have on that output. These examples are from a revision of netperf which used a different command line option syntax. First, TCP_STREAM tests.
<P>
<A HREF="graphics/Netperffl02.gif"><IMG SRC="graphics/Netperffl02th.gif" ></A>This next set of examples is taken from some UDP_STREAM tests. You should notice right away that the output format is slightly different as there can be UDP sends that ``fail&quot; without there being a connection loss. Also, since every UDP datagram sent is not always ``sent&quot; or received, there are more statistics displayed - one line for local statistics and a second line for remote statistics.
<P>
<A HREF="graphics/Netperffl01.gif"><IMG SRC="graphics/Netperffl01th.gif" ></A>This  third set of examples is taken from some  *_RR tests.  These tests use a two-line results format much like that of the UDP_STREAM tests. The only exception is that there are no provisions made for displaying lost packets, as there are not to be any.
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.AR2DBD.91">Section</A> 9. Changes and Fixes in this Release of Netperf</H1>
Revision 2.0 of netperf contains the following changes and fixes:
<P>
<UL>
<LI>On some systems, running netserver as a standalone daemon would result in the 
accumulation of defunct or zombie processes. A call to waitpid has been added to 
netserver so it can &quot;reap&quot; its child processes when they exit.
<LI>The option of confidence intervals has been added to give more assurance that the 
results displayed by netperf are accurate and repeatable. While this will help, it is by 
no means an ironclad guarantee. This is an experiment. The feature has been added 
to the BSD tests only. If they are popular enough, they will be added to the other test 
suites as time permits.
<LI>The test banner output has been modified to give a better indication of the command 
line options used. Also, if CPU utilization measurements are requested, a special letter 
code will be printed in the headers indicating the type of CPU measurement used. More 
information on this feature can be found in Section 3.
<LI>The scripts which ship with netperf have been modified to be more &quot;netperf database 
friendly.&quot; For each datapoint, the netperf command used is echoed to allow 
cut-and-paste into the netperf data submittal form. Also, each datapoint is displayed 
with a full set of test banners - again to facilitate results submission to the database. 
The netperf results database can be accessed with a forms-capable WWW browser at 
the URL http://www.cup.hp.com/netperf/NetperfPage.html.
<LI>The control connection is closed gracefully in a manner similar to that used in the 
TCP_STREAM test. This is intended to fix the problems some users had with the 
UDP_STREAM test which could so swamp the systems involved that the control 
connection could be brought down before the results were successfully transmitted.
<LI>A problem with timeouts in the TCP_RR and UDP_RR test with requests or responses 
much greater than the socket buffer size was fixed. 
<LI>A problem with netserver going into an infinite loop when netperf is terminated with 
Ctrl-C should be fixed in this release.
<LI>On those systems supporting the TCP_MAXSEG option, the TCP MSS used for the 
data connection of a TCP_STREAM, TCP_RR or TCP_CRR test will be displayed 
when the verbosity (-v) is greater than one (1).
<LI>Optional tests for the HP HiPPI interface using LLA have been added. To include these 
in netperf, add a -DDO_HIPPI and recompile. If you would like to use these tests for 
generic LLA performance testing, add an additional -DBUTNOTHIPPI to the 
makefile. WARNING: LLA is an API which will not be supported sometime after 
HP-UX 10.0. The preferred link-level access mechanism is DLPI. Future versions 
of netperf may remove this functionality without warning.
<LI>Optional code to allow pacing of sends has been added/refined. This can be used to 
match the send rate of a sending system in an unreliable _STREAM test (UDP, DLCL, 
Fore, HIPPI) to the rate of the receiver. This feature is enabled by adding a 
-DINTERVALS to the makefile and re-compiling.
<LI>Optional code to keep a histogram of response times for the _RR tests or time spent 
in the send(2) call of a _STREAM test has been added. This feature is enabled by 
adding a -DHISTOGRAM to the makefile and re-compiling. The histogram will be 
displayed when the requested verbosity (global command line option -v) is set to two 
(2) or more. It is known that the extra calls to gettimeofday() affect the measured 
performance.
<LI>Those global and BSD test-specific command line options taking integer values can 
now be specified in &quot;shorthand.&quot; If the number is followed by &quot;K,&quot; &quot;M,&quot; or &quot;G&quot; the 
number will be considered a base and multiplied by 1024, 1024 * 1024, and 1024 * 1024 
* 1024 respectively. If the number is followed by &quot;k,&quot; &quot;m,&quot; or &quot;g&quot; it will be multiplied 
by 1000, 1000 * 1000 or 1000 * 1000 * 1000 respectively. For example, 32K expands to 
32768 and 32k expands to 32000. If this proves useful, it will be migrated to the other 
test suites as well. NOTE the base number must be an integer. Anything after a decimal 
point will be ignored - so 3.2k becomes 3000 and .5m becomes 0.
</UL>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.AR2DBD.B1">Section</A> 10. Known Bugs and Misfeatures</H1>
Revision 2.0 of netperf contains the following known bugs and misfeatures:
<P>
<UL>
<LI>Verbose Output - the logic for greater than standard verbosity is flawed in all tests 
except the TCP_STREAM test. The verbose output for the TCP_STREAM test could 
use some formatting help. When confidence intervals are requested, the verbose 
output will likely be flawed.
<LI>On some systems, the UDP_RR test will fail with with the message ``send_udp_rr: data 
recv error: Connection Refused.&quot; It is unknown if this is a bug in those systems for 
connected UDP sockets, or a bug in netperf.
<LI>Histogram and confidence interval support has been added to the BSD tests only. If 
enough people find them useful, those features could be added to the other test suites.
<LI>The error and warning messages are not localized.
<LI>The supporting documentation is not localized.
<LI>The benchmark is not written to ANSI C. However, an ANSI C compiler is required 
for -DHISTOGRAM compilation. Future versions of the benchmark may require 
ANSI C for all modes of compilation.
<LI>Other API's. Netperf still does not support XTI/TLI, nor does it support WINSOCK.
<LI>The manual shows examples from revisions of netperf using different command line 
syntax. It does not show any DLPI, Unix Domain, or Fore API examples. It does not 
show the enhanced output of Revision 2.0.
<LI>The DLPI Tests are not fully debugged for multivendor or non-Ethernet 
environments.
<LI>The Fore API Tests need better headers.
<LI>The errors reported for remote netperf errors in a Fore API test will almost certainly 
be wrong as netperf does not distinguish between an atm_errno and a standard errno.
<LI>The manual needs troubleshooting information for Unix Domain and Fore tests.
<LI>CPU Utilization measurement is not portable across platforms.
</UL>
If you are feeling adventurous, fixes for these problems would be greatly appreciated ;-)
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.AR2DBD.D1">Section</A> 11. Troubleshooting</H1>
Netperf is a rather simple tool, so its error conditions will be relatively simple and few in 
number.  This section will cover some of the more common error messages and situations you 
might see and offers advice as to what might be wrong and how to correct it.  The error 
messages displayed on non-HP-UX systems might not be the same.
<P>
<B><A NAME="0.2.2Z141Z1.SUJSTF.AR2DBD.E1">establish_control:</A> control socket connect failed: Connection refused</B>
<P>
When this message is displayed, it can mean one of the following:
<P>
<UL>
<LI>Netperf has not been installed on the remote system, or you forgot to run the netserver 
program explicitly. Either install netperf following the instructions at the beginning of 
this document, or run netserver explicitly on the remote system.
<LI>You made a typo in the files <I>/etc/services</I>, or <I>/etc/inetd.conf</I>. Check your entries against 
those in the installation section. If changes are needed, make them and then 
reconfigure inetd as described in the installation section.
<LI>You forgot to reconfigure inetd. Reconfigure inetd following the instructions in the 
installation section.
<LI>You specified a port number with the -p option to netperf that is not the same as the 
port number being used by the netserver program on the remote system.
<LI>Inetd security on the remote system is not configured to allow connections from the 
local system. Follow the instructions in the manpage for inetd.sec.
<LI>Netperf hates you. It has always hated you. Consult the job listings in misc.jobs.offered 
and start your life over :)
</UL>
<B><A NAME="0.2.2Z141Z1.SUJSTF.BR2DBD.F1">udp_send:</A> data send error: Message too long <BR>
-or-<BR>
send_udp_rr: data send error: Message too long</B>
<P>
These messages indicate the following:
<P>
<UL>
<LI>You have requested a send size (-m option) or request size (-r option) that is larger 
than the local socket send buffer size (-s option) with a UDP_STREAM or UDP_RR 
test (-t option). You should either increase the size of the socket buffer, or decrease 
the size of the send/request.
</UL>
<B><A NAME="0.2.2Z141Z1.SUJSTF.BR2DBD.G1">put_control:</A> acknowledgement error wanted 6 got 5<BR>
netperf: dl_open: could not sent control message, errno = 0<BR>
netperf: send_dlpi_co_stream: dlpi_stream data descriptor: Error 0</B>
<P>
This stream of messages indicates the following:
<P>
<UL>
<LI>You have specified a DLPI PPA that is not valid. Verify the correct PPA and try again. 
Variations on this stream of messages can be seen for each of the DLPI tests.
</UL>
<B><A NAME="0.2.2Z141Z1.SUJSTF.BR2DBD.H1">netperf:</A> dl_open: open of /dev/foo failed, errno = 2<BR>
netperf: send_dlpi_co_stream: dlpi stream data descriptor: No such file or directory</B>
<P>
This stream of messages indicates the following:
<P>
<UL>
<LI>You have specified a DLPI device file that is not valid. Verify the device file name  and 
try again. Defaults for DLPI device files will vary from OS to OS. Variations on this 
stream of messages can be seen for each of the DLPI tests.
</UL>
<B><A NAME="0.2.2Z141Z1.SUJSTF.BR2DBD.I1">netperf:</A> receive_response: no response received</B>
<P>
This message indicates that netperf was expecting to receive a response on its control 
connection, but none was received within the timeout period. In  some cases, this could be the 
result of the operating system restarting system calls that netperf/netserver expects to exit with 
an errno of EINTR.
<P>
Of course, there may be other problems that are not covered by this section. Comments and 
questions pertaining to both this document and netperf are encouraged. Please feel free to 
send them to:
<P>
<B>raj@cup.hp.com</B>
<P>
Alternatively, the IND Networking Performance Team does try to read the Internet 
newsgroups comp.sys.hp.*, comp.protocols.tcp-ip, comp.benchmarks and the HP internal 
newsgroups pertaining to networking and performance.
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.BR2DBD.K1">Section</A> 12. Glossary</H1>
DLPI	<B>D</B>ata <B>L</B>ink <B>P</B>rovider <B>I</B>nterface. This is a standardized Link-Level 
Access (Level 2 of the OSI Reference Model) API. This interface 
is discussed in many books on Streams programming. The DLPI 
Version 2 Reference can be retrieved via anonymous FTP from 
col.hp.com.
<P>
TCP		<B>T</B>ransmission <B>C</B>ontrol <B>P</B>rotocol. This defines a reliable, 
byte-stream protocol for exchanging information between two 
hosts. 
<P>
UDP	<B>U</B>ser <B>D</B>atagram <B>P</B>rotocol. This defines an unreliable, 
message-oriented protocol for exchanging information between 
two hosts.
<P>
TLI		<B>T</B>ransport <B>L</B>ayer <B>I</B>nterface. This is a standardized Transport level 
(Level 4 of the OSI Reference Model) API. This interface can be 
used in conjunction with many different transport protocols, 
including TCP, and the OSI Transports (TP0 through TP4). Often 
found in Streams implementations.
<P>
XTI		X/Open Transport Interface. This is a TLI-like (very TLI-like 
actually) Transport level API. The definition of XTI is 
maintained by X/Open.
<P>
IP		<B>I</B>nternet <B>P</B>rotocol. This protocol is the ``glue&quot; between TCP/UDP 
and the Link-Level. It provides the services of routing and 
packet segmentation and reassembly to export the illusion of a 
single homogenous network to the higher protocols.
<P>
<H1><A NAME="0.2.2Z141Z1.SUJSTF.BR2DBD.M1">Section</A> 13. The Netperf Database</H1>
An online database of netperf results is available to anyone with a forms-capable WWW 
browser and access to the Internet. The URL to follow is:
<P>
<B>http://www.cup.hp.com/netperf/NetperfPage.html</B>
<P>
From there you can search or browse the database, or better still, submit numbers! There are 
additional links which will allow you to download copies of the benchmark or find other 
sources of network performance information.
<P>


</BODY>
</HTML>
